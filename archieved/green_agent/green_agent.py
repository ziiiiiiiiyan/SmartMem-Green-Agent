"""
Green Agent v2.0 - æµ‹è¯•ç”¨ä¾‹è‡ªåŠ¨ç”Ÿæˆå™¨ï¼ˆå¸¦éªŒè¯å±‚ï¼‰

ç”¨äºä¸º SmartMem æ™ºèƒ½å®¶å±… Agent ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ•°æ®åº“ã€‚
åŸºäºæœ¬åœ° Ollama + Qwen2.5-Coder æ¨¡å‹ã€‚

æ”¹è¿›ç‚¹ï¼š
1. æ›´ç²¾ç¡®çš„ Prompt è®¾è®¡ï¼ˆåŸºäº test_case_spec.mdï¼‰
2. ä¸¥æ ¼çš„è®¾å¤‡çº¦æŸéªŒè¯
3. è‡ªåŠ¨è¿‡æ»¤æ— æ•ˆæµ‹è¯•ç”¨ä¾‹
4. é‡è¯•æœºåˆ¶

ä½¿ç”¨æ–¹æ³•:
    python green_agent.py --level easy --count 5
    python green_agent.py --level all --count 10 --retry 3
"""

import json
import argparse
from datetime import datetime
from pathlib import Path
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Literal, Tuple
from openai import OpenAI

# ============== é…ç½®éƒ¨åˆ† ==============

OLLAMA_BASE_URL = "http://localhost:11434/v1"
OLLAMA_API_KEY = "ollama"
MODEL_NAME = "qwen2.5-coder:7b"

# ä¸¥æ ¼çš„è®¾å¤‡çº¦æŸå®šä¹‰ï¼ˆä¸ interface_spec.md å®Œå…¨ä¸€è‡´ï¼‰
DEVICE_CONSTRAINTS = {
    # Living Room
    "living_room_light": {"type": "enum", "values": ["on", "off"]},
    "living_room_color": {"type": "enum", "values": ["white", "red", "blue", "warm"]},
    # Bedroom
    "bedroom_light": {"type": "enum", "values": ["on", "off"]},
    "bedroom_color": {"type": "enum", "values": ["white", "warm", "blue", "red"]},
    # Climate Control
    "ac": {"type": "enum", "values": ["on", "off"]},
    "ac_temperature": {"type": "int", "min": 16, "max": 30},
    "fan_speed": {"type": "enum", "values": ["off", "low", "medium", "high"]},
    # Entertainment & Security
    "music_volume": {"type": "int", "min": 0, "max": 10},
    "front_door_lock": {"type": "enum", "values": ["locked", "unlocked"]},
    "kitchen_light": {"type": "enum", "values": ["on", "off"]},
}

VALID_DEVICE_KEYS = list(DEVICE_CONSTRAINTS.keys())

# æµ‹è¯•ç»´åº¦
DIMENSIONS = ["precision", "ambiguous", "conflict", "memory", "noise"]


# ============== éªŒè¯å™¨ ==============

class TestCaseValidator:
    """æµ‹è¯•ç”¨ä¾‹éªŒè¯å™¨ - ç¡®ä¿ç”Ÿæˆçš„ç”¨ä¾‹ç¬¦åˆè§„èŒƒ"""
    
    @staticmethod
    def validate_device_key(key: str) -> Tuple[bool, str]:
        """éªŒè¯è®¾å¤‡ key æ˜¯å¦æœ‰æ•ˆ"""
        if key not in VALID_DEVICE_KEYS:
            return False, f"æ— æ•ˆçš„è®¾å¤‡ key: '{key}'ï¼Œæœ‰æ•ˆå€¼: {VALID_DEVICE_KEYS}"
        return True, ""
    
    @staticmethod
    def validate_device_value(key: str, value: Any) -> Tuple[bool, str]:
        """éªŒè¯è®¾å¤‡å€¼æ˜¯å¦ç¬¦åˆçº¦æŸ"""
        if key not in DEVICE_CONSTRAINTS:
            return False, f"æœªçŸ¥è®¾å¤‡: {key}"
        
        constraint = DEVICE_CONSTRAINTS[key]
        
        if constraint["type"] == "enum":
            if value not in constraint["values"]:
                return False, f"è®¾å¤‡ '{key}' çš„å€¼ '{value}' æ— æ•ˆï¼Œå…è®¸å€¼: {constraint['values']}"
        elif constraint["type"] == "int":
            if not isinstance(value, int):
                return False, f"è®¾å¤‡ '{key}' çš„å€¼å¿…é¡»æ˜¯æ•´æ•°ï¼Œå¾—åˆ°: {type(value).__name__}"
            if not (constraint["min"] <= value <= constraint["max"]):
                return False, f"è®¾å¤‡ '{key}' çš„å€¼ {value} è¶…å‡ºèŒƒå›´ [{constraint['min']}, {constraint['max']}]"
        
        return True, ""
    
    @classmethod
    def validate_test_case(cls, test_case: dict) -> Tuple[bool, List[str]]:
        """å®Œæ•´éªŒè¯æµ‹è¯•ç”¨ä¾‹"""
        errors = []
        
        # 1. éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['scenario_id', 'difficulty', 'dimension', 'description', 'turns']
        for field in required_fields:
            if field not in test_case:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        if errors:
            return False, errors
        
        # 2. éªŒè¯ initial_state
        if 'initial_state' in test_case and test_case['initial_state']:
            for key, value in test_case['initial_state'].items():
                valid, msg = cls.validate_device_key(key)
                if not valid:
                    errors.append(f"initial_state: {msg}")
                    continue
                valid, msg = cls.validate_device_value(key, value)
                if not valid:
                    errors.append(f"initial_state: {msg}")
        
        # 3. éªŒè¯æ¯ä¸ª turn
        for i, turn in enumerate(test_case.get('turns', [])):
            turn_id = turn.get('turn_id', i + 1)
            
            # éªŒè¯ turn ç»“æ„
            if 'gm_instruction' not in turn:
                errors.append(f"Turn {turn_id}: ç¼ºå°‘ gm_instruction")
            if 'expected_agent_action' not in turn:
                errors.append(f"Turn {turn_id}: ç¼ºå°‘ expected_agent_action")
            if 'expected_final_state' not in turn:
                errors.append(f"Turn {turn_id}: ç¼ºå°‘ expected_final_state")
            
            # éªŒè¯ actions
            for j, action in enumerate(turn.get('expected_agent_action', [])):
                if 'key' not in action:
                    errors.append(f"Turn {turn_id} Action {j+1}: ç¼ºå°‘ key")
                    continue
                if 'value' not in action:
                    errors.append(f"Turn {turn_id} Action {j+1}: ç¼ºå°‘ value")
                    continue
                
                key = action['key']
                value = action['value']
                
                valid, msg = cls.validate_device_key(key)
                if not valid:
                    errors.append(f"Turn {turn_id} Action {j+1}: {msg}")
                    continue
                
                valid, msg = cls.validate_device_value(key, value)
                if not valid:
                    errors.append(f"Turn {turn_id} Action {j+1}: {msg}")
            
            # éªŒè¯ expected_final_state
            for key, value in turn.get('expected_final_state', {}).items():
                valid, msg = cls.validate_device_key(key)
                if not valid:
                    errors.append(f"Turn {turn_id} expected_final_state: {msg}")
                    continue
                valid, msg = cls.validate_device_value(key, value)
                if not valid:
                    errors.append(f"Turn {turn_id} expected_final_state: {msg}")
        
        # 4. éªŒè¯çŠ¶æ€ä¸€è‡´æ€§ï¼ˆexpected_final_state åº”è¯¥ä¸ actions ä¸€è‡´ï¼‰
        if not errors:
            state_errors = cls._validate_state_consistency(test_case)
            errors.extend(state_errors)
        
        return len(errors) == 0, errors
    
    @classmethod
    def _validate_state_consistency(cls, test_case: dict) -> List[str]:
        """éªŒè¯çŠ¶æ€ä¸€è‡´æ€§ï¼šactions æ‰§è¡Œåçš„çŠ¶æ€åº”è¯¥ä¸ expected_final_state ä¸€è‡´"""
        errors = []
        
        # æ¨¡æ‹ŸçŠ¶æ€
        current_state = dict(test_case.get('initial_state', {}))
        
        for turn in test_case.get('turns', []):
            turn_id = turn.get('turn_id', 0)
            
            # æ‰§è¡Œ actions
            for action in turn.get('expected_agent_action', []):
                if action.get('action') == 'update':
                    key = action.get('key')
                    value = action.get('value')
                    if key:
                        current_state[key] = value
            
            # æ£€æŸ¥ expected_final_state
            expected_state = turn.get('expected_final_state', {})
            for key, expected_value in expected_state.items():
                actual_value = current_state.get(key)
                if actual_value != expected_value:
                    # å¦‚æœåœ¨ initial_state ä¸­ä¹Ÿæ²¡æœ‰ï¼Œå¯èƒ½æ˜¯é—æ¼
                    if key not in current_state:
                        errors.append(
                            f"Turn {turn_id}: expected_final_state ä¸­çš„ '{key}={expected_value}' "
                            f"æ—¢ä¸åœ¨ initial_state ä¸­ï¼Œä¹Ÿæ²¡æœ‰è¢«ä»»ä½• action è®¾ç½®"
                        )
        
        return errors


# ============== æ•°æ®ç»“æ„ ==============

class ExpectedAction(BaseModel):
    action: Literal["update"] = "update"
    key: str
    value: Any


class Turn(BaseModel):
    turn_id: int
    gm_instruction: str
    expected_agent_action: List[ExpectedAction] = Field(default_factory=list)
    expected_final_state: Dict[str, Any]


class TestCase(BaseModel):
    scenario_id: str
    difficulty: Literal["easy", "medium", "difficult"]
    dimension: str
    description: str
    initial_state: Dict[str, Any] = Field(default_factory=dict)
    turns: List[Turn]


class TestCaseDatabase(BaseModel):
    metadata: Dict[str, Any] = Field(default_factory=dict)
    test_cases: List[TestCase] = Field(default_factory=list)


# ============== Green Agent æ ¸å¿ƒ ==============

class GreenAgent:
    """Green Agent v2.0 - å¸¦éªŒè¯å±‚çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨"""
    
    def __init__(
        self, 
        base_url: str = OLLAMA_BASE_URL, 
        api_key: str = OLLAMA_API_KEY, 
        model: str = MODEL_NAME,
        max_retries: int = 3,
        provider: str = "ollama"  # æ–°å¢: API provider ç±»å‹
    ):
        self.provider = provider
        self.model = model
        self.max_retries = max_retries
        self.validator = TestCaseValidator()
        
        # æ ¹æ® provider åˆå§‹åŒ–å®¢æˆ·ç«¯
        if provider == "anthropic":
            try:
                from anthropic import Anthropic
                self.client = Anthropic(api_key=api_key)
                self._call_llm = self._call_anthropic
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£… anthropic: pip install anthropic")
        else:
            # OpenAI å…¼å®¹ API (åŒ…æ‹¬ Ollama, OpenAI, DeepSeek ç­‰)
            self.client = OpenAI(base_url=base_url, api_key=api_key)
            self._call_llm = self._call_openai
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_attempts": 0,
            "successful": 0,
            "failed_json": 0,
            "failed_validation": 0,
        }
    
    @classmethod
    def from_config(cls, config, max_retries: int = 3):
        """ä» APIConfig åˆ›å»ºå®ä¾‹"""
        from green_agent.api_config import APIConfig
        
        if isinstance(config, str):
            from green_agent.api_config import get_api_config
            config = get_api_config(config)
        
        return cls(
            base_url=config.base_url,
            api_key=config.api_key,
            model=config.model,
            max_retries=max_retries,
            provider=config.provider
        )
    
    @classmethod
    def from_ollama(cls, model: str = "qwen2.5-coder:7b", **kwargs):
        """ä» Ollama æœ¬åœ°åˆ›å»º"""
        return cls(
            base_url="http://localhost:11434/v1",
            api_key="ollama",
            model=model,
            provider="ollama",
            **kwargs
        )
    
    @classmethod
    def from_openai(cls, model: str = "gpt-4o", api_key: Optional[str] = None, **kwargs):
        """ä» OpenAI API åˆ›å»º"""
        import os
        return cls(
            base_url="https://api.openai.com/v1",
            api_key=api_key or os.getenv("OPENAI_API_KEY", ""),
            model=model,
            provider="openai",
            **kwargs
        )
    
    @classmethod
    def from_anthropic(cls, model: str = "claude-3-5-sonnet-20241022", api_key: Optional[str] = None, **kwargs):
        """ä» Anthropic Claude API åˆ›å»º"""
        import os
        return cls(
            base_url="https://api.anthropic.com",
            api_key=api_key or os.getenv("ANTHROPIC_API_KEY", ""),
            model=model,
            provider="anthropic",
            **kwargs
        )
    
    @classmethod
    def from_deepseek(cls, model: str = "deepseek-chat", api_key: Optional[str] = None, **kwargs):
        """ä» DeepSeek API åˆ›å»º"""
        import os
        return cls(
            base_url="https://api.deepseek.com/v1",
            api_key=api_key or os.getenv("DEEPSEEK_API_KEY", ""),
            model=model,
            provider="deepseek",
            **kwargs
        )
    
    @classmethod
    def from_openrouter(cls, model: str = "anthropic/claude-3.5-sonnet", api_key: Optional[str] = None, **kwargs):
        """ä» OpenRouter åˆ›å»º (å¤šæ¨¡å‹ç½‘å…³)"""
        import os
        return cls(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key or os.getenv("OPENROUTER_API_KEY", ""),
            model=model,
            provider="openrouter",
            **kwargs
        )
    
    def _call_openai(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ OpenAI å…¼å®¹ API"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=4096
        )
        return response.choices[0].message.content
    
    def _call_anthropic(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ Anthropic Claude API"""
        response = self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.content[0].text
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç²¾ç¡®çš„ç³»ç»Ÿæç¤ºè¯"""
        
        # æ„å»ºè®¾å¤‡çº¦æŸå­—ç¬¦ä¸²
        device_specs = []
        for key, constraint in DEVICE_CONSTRAINTS.items():
            if constraint["type"] == "enum":
                device_specs.append(f'- {key}: {constraint["values"]}')
            else:
                device_specs.append(f'- {key}: integer {constraint["min"]}-{constraint["max"]}')
        
        device_spec_str = "\n".join(device_specs)
        
        return f"""You are a QA Engineer Agent for SmartMem, a smart home AI testing system.
Generate test cases in STRICTLY VALID JSON format.

## CRITICAL RULES - MUST FOLLOW:
1. Output ONLY raw JSON - NO markdown, NO code blocks, NO explanations
2. Device keys MUST be exactly from the allowed list (case-sensitive)
3. Device values MUST match the exact allowed values or ranges
4. expected_final_state MUST be consistent with initial_state + actions

## DEVICE SPECIFICATIONS (EXACT VALUES ONLY):
{device_spec_str}

## IMPORTANT CONSTRAINTS:
- "living_room_light" and "bedroom_light" and "kitchen_light" can ONLY be "on" or "off"
- Colors ("living_room_color", "bedroom_color") can ONLY be "white", "red", "blue", or "warm"
- "fan_speed" can ONLY be "off", "low", "medium", or "high" (NOT integers!)
- "ac" can ONLY be "on" or "off"
- "front_door_lock" can ONLY be "locked" or "unlocked"
- Integer values: ac_temperature (16-30), music_volume (0-10)

## TEST CASE ENCODING SYSTEM:
- A1: Precise command (e.g., "Set AC to 26")
- A2: Ambiguous command (e.g., "Make it cozy")
- A3: Conflicting commands (e.g., "Turn on... wait, turn off")
- A4: State query (e.g., "Is the light on?")
- B0: No action (distractor turn)
- B1: Single device action
- B2: Multiple independent device actions
- B3: Sequential dependent actions
- N0: No noise
- N1: Light chitchat noise
- N2: Logic puzzle noise
- N3: Heavy text noise

## OUTPUT FORMAT:
{{
  "scenario_id": "scenario_A1_B1_C0_N0",
  "difficulty": "easy|medium|difficult",
  "dimension": "precision|ambiguous|conflict|memory|noise",
  "description": "Brief English description",
  "initial_state": {{"device_key": "valid_value"}},
  "turns": [
    {{
      "turn_id": 1,
      "gm_instruction": "User instruction",
      "expected_agent_action": [
        {{"action": "update", "key": "device_key", "value": "valid_value"}}
      ],
      "expected_final_state": {{"device_key": "valid_value"}}
    }}
  ]
}}
"""

    def _build_user_prompt(self, difficulty: str, dimension: str, scenario_number: int) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯"""
        
        difficulty_specs = {
            "easy": """
## EASY Level Specifications:
- Turns: 1-2 maximum
- Intent: A1 (precise commands only)
- Actions: B1 (single device per turn)
- Noise: N0 (none)
- Memory: C0 (immediate)

Example scenarios:
1. "Turn on the living room light" -> living_room_light: "on"
2. "Set the AC temperature to 24 degrees" -> ac_temperature: 24
3. "Lock the front door" -> front_door_lock: "locked"
""",
            "medium": """
## MEDIUM Level Specifications:
- Turns: 2-4
- Intent: A2 (may need reasoning) or A3 (simple conflicts)
- Actions: B1-B2 (single or multiple devices)
- Noise: N0-N1 (0-1 distractor turns allowed)
- Memory: C0-C1 (0-2 turns gap)

Example scenarios:
1. "Make the living room cozy for reading" -> light: on, color: warm, maybe adjust volume
2. "It's too hot" then "Actually it's fine" -> temperature change then revert
3. Distractor: "What's the weather like?" with expected_agent_action: []
""",
            "difficult": """
## DIFFICULT Level Specifications:
- Turns: 4-8
- Intent: A3 (conflicts) or A4 (state queries) mixed with A1/A2
- Actions: B2-B3 (multiple devices, may have order dependency)
- Noise: N1-N3 (2-4 distractor turns between key commands)
- Memory: C2-C3 (recall state from 3+ turns ago)

Example scenario structure:
Turn 1: Set music_volume to 5
Turn 2-4: Distractor turns (chitchat, unrelated topics) with expected_agent_action: []
Turn 5: "Turn it up by 2" -> Agent must remember volume was 5, set to 7
"""
        }
        
        dimension_specs = {
            "precision": "Test EXACT command following. User gives precise values. No ambiguity.",
            "ambiguous": "Test INFERENCE ability. Commands like 'make it comfortable' require reasoning about multiple devices.",
            "conflict": "Test CONFLICT resolution. Include contradictory commands. Later command wins.",
            "memory": "Test STATE RECALL. Set a value, add distractors, then ask to modify based on the old value.",
            "noise": "Test NOISE resistance. Many distractor turns with expected_agent_action: [] between real commands.",
        }
        
        return f"""Generate ONE test case:

DIFFICULTY: {difficulty.upper()}
{difficulty_specs.get(difficulty, difficulty_specs['easy'])}

DIMENSION: {dimension}
{dimension_specs.get(dimension, 'Standard test scenario.')}

SCENARIO NUMBER: {scenario_number}

REMINDERS:
1. Use EXACT device keys: living_room_light, bedroom_light, ac, ac_temperature, etc.
2. Use EXACT values: "on"/"off" for lights, "locked"/"unlocked" for door, integers for temperature/volume
3. fan_speed uses strings: "off", "low", "medium", "high" (NOT numbers!)
4. expected_final_state must include ALL devices that have been modified
5. Distractor turns MUST have: expected_agent_action: []

Output ONLY the JSON object, starting with {{ and ending with }}
"""

    def generate_single_case(
        self,
        difficulty: str = "easy",
        dimension: str = "precision",
        scenario_number: int = 1
    ) -> Optional[TestCase]:
        """ç”Ÿæˆå•ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œå¸¦éªŒè¯å’Œé‡è¯•"""
        
        for attempt in range(self.max_retries):
            self.stats["total_attempts"] += 1
            
            attempt_str = f" (å°è¯• {attempt + 1}/{self.max_retries})" if attempt > 0 else ""
            print(f"ğŸŸ¢ Green Agent ç”Ÿæˆä¸­{attempt_str}... [éš¾åº¦: {difficulty}, ç»´åº¦: {dimension}]")
            
            try:
                system_prompt = self._build_system_prompt()
                user_prompt = self._build_user_prompt(difficulty, dimension, scenario_number)
                
                # ä½¿ç”¨ç»Ÿä¸€çš„ LLM è°ƒç”¨æ¥å£
                raw_content = self._call_llm(system_prompt, user_prompt)
                
                # 1. JSON è§£æ - å°è¯•æå– JSON
                try:
                    data = json.loads(raw_content)
                except json.JSONDecodeError:
                    # å°è¯•ä»å“åº”ä¸­æå– JSON
                    import re
                    json_match = re.search(r'\{[\s\S]*\}', raw_content)
                    if json_match:
                        try:
                            data = json.loads(json_match.group())
                        except json.JSONDecodeError as e:
                            print(f"  âš ï¸  JSON è§£æå¤±è´¥: {e}")
                            self.stats["failed_json"] += 1
                            continue
                    else:
                        print(f"  âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆ JSON")
                        self.stats["failed_json"] += 1
                        continue
                
                # 2. è¯­ä¹‰éªŒè¯
                is_valid, errors = self.validator.validate_test_case(data)
                
                if not is_valid:
                    print(f"  âš ï¸  éªŒè¯å¤±è´¥:")
                    for err in errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                        print(f"      - {err}")
                    if len(errors) > 3:
                        print(f"      ... è¿˜æœ‰ {len(errors) - 3} ä¸ªé”™è¯¯")
                    self.stats["failed_validation"] += 1
                    continue
                
                # 3. æ„å»º Pydantic æ¨¡å‹
                test_case = TestCase(**data)
                
                print(f"  âœ… ç”ŸæˆæˆåŠŸ: {test_case.scenario_id}")
                self.stats["successful"] += 1
                return test_case
                
            except Exception as e:
                print(f"  ğŸ”´ ç”Ÿæˆå¼‚å¸¸: {e}")
                continue
        
        print(f"  âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æ­¤ç”¨ä¾‹")
        return None

    def generate_batch(
        self,
        difficulty: str = "all",
        dimension: str = "all",
        count_per_combo: int = 2
    ) -> TestCaseDatabase:
        """æ‰¹é‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        
        difficulties = ["easy", "medium", "difficult"] if difficulty == "all" else [difficulty]
        dimensions = DIMENSIONS if dimension == "all" else [dimension]
        
        database = TestCaseDatabase(
            metadata={
                "version": "2.1-green-validated",
                "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "generator": "Green Agent v2.0",
                "model": self.model,
                "validation": "strict",
                "notes": f"Difficulties: {difficulties}, Dimensions: {dimensions}"
            },
            test_cases=[]
        )
        
        scenario_counter = 1
        for diff in difficulties:
            for dim in dimensions:
                for i in range(count_per_combo):
                    case = self.generate_single_case(diff, dim, scenario_counter)
                    if case:
                        database.test_cases.append(case)
                        scenario_counter += 1
        
        # æ‰“å°ç»Ÿè®¡
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        print(f"   æ€»å°è¯•æ¬¡æ•°: {self.stats['total_attempts']}")
        print(f"   æˆåŠŸ: {self.stats['successful']}")
        print(f"   JSON è§£æå¤±è´¥: {self.stats['failed_json']}")
        print(f"   éªŒè¯å¤±è´¥: {self.stats['failed_validation']}")
        print(f"   æˆåŠŸç‡: {self.stats['successful'] / max(1, self.stats['total_attempts']) * 100:.1f}%")
        print(f"{'='*60}")
        
        return database

    def save_database(self, database: TestCaseDatabase, output_path: str) -> None:
        """ä¿å­˜æ•°æ®åº“åˆ° JSON æ–‡ä»¶"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(database.model_dump_json(indent=2))
        
        print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")


# ============== å‘½ä»¤è¡Œæ¥å£ ==============

def main():
    parser = argparse.ArgumentParser(
        description="Green Agent v2.0 - SmartMem æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆå¸¦éªŒè¯ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python green_agent.py --level easy --count 3
  python green_agent.py --level medium --dimension memory --count 5
  python green_agent.py --level all --dimension all --count 2
  python green_agent.py --single --level difficult --dimension conflict --retry 5
        """
    )
    
    parser.add_argument("--level", "-l", choices=["easy", "medium", "difficult", "all"], default="easy")
    parser.add_argument("--dimension", "-d", choices=DIMENSIONS + ["all"], default="precision")
    parser.add_argument("--count", "-c", type=int, default=3)
    parser.add_argument("--output", "-o", default="test_cases/green_generated.json")
    parser.add_argument("--single", "-s", action="store_true", help="ä»…ç”Ÿæˆå•ä¸ªç”¨ä¾‹")
    parser.add_argument("--retry", "-r", type=int, default=3, help="éªŒè¯å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°")
    parser.add_argument("--model", "-m", default=MODEL_NAME)
    parser.add_argument("--base-url", "-u", default=OLLAMA_BASE_URL)
    
    args = parser.parse_args()
    
    agent = GreenAgent(
        base_url=args.base_url,
        model=args.model,
        max_retries=args.retry
    )
    
    print("=" * 60)
    print("ğŸŸ¢ Green Agent v2.0 - æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆå¸¦éªŒè¯ï¼‰")
    print("=" * 60)
    print(f"æ¨¡å‹: {args.model}")
    print(f"éš¾åº¦: {args.level}")
    print(f"ç»´åº¦: {args.dimension}")
    print(f"æœ€å¤§é‡è¯•: {args.retry}")
    print("=" * 60 + "\n")
    
    if args.single:
        case = agent.generate_single_case(
            difficulty=args.level if args.level != "all" else "easy",
            dimension=args.dimension if args.dimension != "all" else "precision",
            scenario_number=1
        )
        if case:
            print("\nâœ… ç”ŸæˆæˆåŠŸï¼\n")
            print(case.model_dump_json(indent=2))
    else:
        database = agent.generate_batch(
            difficulty=args.level,
            dimension=args.dimension,
            count_per_combo=args.count
        )
        
        if database.test_cases:
            agent.save_database(database, args.output)
            print(f"\nğŸ‰ å®Œæˆï¼å…±ç”Ÿæˆ {len(database.test_cases)} ä¸ªæœ‰æ•ˆæµ‹è¯•ç”¨ä¾‹")
        else:
            print("\nâŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•æœ‰æ•ˆæµ‹è¯•ç”¨ä¾‹")


if __name__ == "__main__":
    main()
