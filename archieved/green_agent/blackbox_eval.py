"""
Eval æ¡†æ¶ - é»‘ç›’è¯„ä¼°å™¨

è®¾è®¡åŸåˆ™ï¼š
1. Agent æ˜¯é»‘ç›’ï¼Œåªé€šè¿‡æ–‡æœ¬ I/O äº¤äº’
2. Eval æä¾›ç¯å¢ƒå’Œå·¥å…·å‡½æ•°
3. Agent è‡ªè¡Œå†³å®šå¦‚ä½•æ³¨å†Œå’Œä½¿ç”¨å·¥å…·
4. è¯„åˆ†åŸºäºæœ€ç»ˆçŠ¶æ€å’ŒåŠ¨ä½œåºåˆ—

æ¥å£å¯¹é½ï¼š
- Eval ç«¯: èµ·ç¯å¢ƒ + æä¾›å·¥å…·å‡½æ•° + è§£æå“åº” + è¯„åˆ†
- Agent ç«¯: æ¥æ”¶æŒ‡ä»¤ -> è¿”å›æ–‡æœ¬å“åº” (å¯åŒ…å«å·¥å…·è°ƒç”¨)
"""

import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
import json
import re

sys.path.insert(0, str(Path(__file__).parent.parent))

from app.environment import SmartHomeEnv
from app.evaluator import TurnEvaluator
from green_agent.agent_interface import AgentInterface, create_agent


# ============== å·¥å…·å‡½æ•°å®šä¹‰ ==============

TOOL_FUNCTIONS = {
    "manage_living_room_light": {
        "description": "Control the living room light",
        "parameters": {"state": {"type": "string", "enum": ["on", "off"]}}
    },
    "manage_living_room_color": {
        "description": "Set the living room light color",
        "parameters": {"color": {"type": "string", "enum": ["warm", "cool"]}}
    },
    "manage_bedroom_light": {
        "description": "Control the bedroom light",
        "parameters": {"state": {"type": "string", "enum": ["on", "off"]}}
    },
    "manage_bedroom_color": {
        "description": "Set the bedroom light color",
        "parameters": {"color": {"type": "string", "enum": ["warm", "cool"]}}
    },
    "manage_ac_power": {
        "description": "Control the air conditioner power",
        "parameters": {"state": {"type": "string", "enum": ["on", "off"]}}
    },
    "manage_ac_temperature": {
        "description": "Set the AC temperature (16-30)",
        "parameters": {"temperature": {"type": "integer", "minimum": 16, "maximum": 30}}
    },
    "manage_fan_speed": {
        "description": "Set the fan speed",
        "parameters": {"speed": {"type": "string", "enum": ["low", "medium", "high", "off"]}}
    },
    "manage_music_volume": {
        "description": "Set the music volume (0-100)",
        "parameters": {"volume": {"type": "integer", "minimum": 0, "maximum": 100}}
    },
    "manage_front_door_lock": {
        "description": "Control the front door lock",
        "parameters": {"state": {"type": "string", "enum": ["locked", "unlocked"]}}
    },
    "manage_kitchen_light": {
        "description": "Control the kitchen light",
        "parameters": {"state": {"type": "string", "enum": ["on", "off"]}}
    },
    "read_all_states": {
        "description": "Read the current state of all devices",
        "parameters": {}
    }
}

# å·¥å…·ååˆ°è®¾å¤‡é”®çš„æ˜ å°„
TOOL_TO_DEVICE = {
    "manage_living_room_light": "living_room_light",
    "manage_living_room_color": "living_room_color",
    "manage_bedroom_light": "bedroom_light",
    "manage_bedroom_color": "bedroom_color",
    "manage_ac_power": "ac_power",
    "manage_ac_temperature": "ac_temperature",
    "manage_fan_speed": "fan_speed",
    "manage_music_volume": "music_volume",
    "manage_front_door_lock": "front_door_lock",
    "manage_kitchen_light": "kitchen_light"
}


# ============== å“åº”è§£æå™¨ ==============

class ResponseParser:
    """
    ä» Agent å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨
    
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. JSON æ ¼å¼: {"action": "update", "key": "...", "value": ...}
    2. å‡½æ•°è°ƒç”¨æ ¼å¼: manage_ac_temperature(25)
    3. OpenAI Tool Calls æ ¼å¼
    """
    
    @staticmethod
    def parse(response: str) -> List[Dict[str, Any]]:
        """è§£æå“åº”ï¼Œè¿”å›æ ‡å‡†åŒ–çš„åŠ¨ä½œåˆ—è¡¨"""
        actions = []
        
        # 1. è§£æ JSON åŠ¨ä½œæ ¼å¼
        actions.extend(ResponseParser._parse_json_actions(response))
        
        # 2. è§£æå‡½æ•°è°ƒç”¨æ ¼å¼
        actions.extend(ResponseParser._parse_function_calls(response))
        
        # 3. è§£æ OpenAI Tool Calls æ ¼å¼
        actions.extend(ResponseParser._parse_openai_tool_calls(response))
        
        # å»é‡
        seen = set()
        unique_actions = []
        for action in actions:
            key = (action.get('key'), str(action.get('value')))
            if key not in seen:
                seen.add(key)
                unique_actions.append(action)
        
        return unique_actions
    
    @staticmethod
    def _parse_json_actions(response: str) -> List[Dict[str, Any]]:
        """è§£æ JSON æ ¼å¼çš„åŠ¨ä½œ"""
        actions = []
        
        # åŒ¹é… {"action": "update", ...} æ ¼å¼
        json_pattern = r'\{[^{}]*"action"\s*:\s*"update"[^{}]*\}'
        matches = re.findall(json_pattern, response, re.IGNORECASE)
        
        for match in matches:
            try:
                action = json.loads(match)
                if 'key' in action and 'value' in action:
                    actions.append({
                        "action": "update",
                        "key": action['key'],
                        "value": action['value']
                    })
            except json.JSONDecodeError:
                continue
        
        return actions
    
    @staticmethod
    def _parse_function_calls(response: str) -> List[Dict[str, Any]]:
        """è§£æå‡½æ•°è°ƒç”¨æ ¼å¼"""
        actions = []
        
        # åŒ¹é… manage_xxx(value) æˆ– manage_xxx(key=value) æ ¼å¼
        func_pattern = r'manage_(\w+)\s*\(\s*([^)]+)\s*\)'
        
        for match in re.finditer(func_pattern, response):
            device = match.group(1)
            args_str = match.group(2).strip()
            
            # å¤„ç†è®¾å¤‡åæ˜ å°„
            full_device = None
            for tool_name, dev_key in TOOL_TO_DEVICE.items():
                if tool_name == f"manage_{device}":
                    full_device = dev_key
                    break
            
            if not full_device:
                # å°è¯•ç›´æ¥ä½¿ç”¨
                full_device = device
            
            # è§£æå‚æ•°å€¼
            value = ResponseParser._parse_arg_value(args_str)
            
            if value is not None:
                actions.append({
                    "action": "update",
                    "key": full_device,
                    "value": value
                })
        
        return actions
    
    @staticmethod
    def _parse_openai_tool_calls(response: str) -> List[Dict[str, Any]]:
        """è§£æ OpenAI Tool Calls æ ¼å¼"""
        actions = []
        
        # åŒ¹é… [Tool Calls: ...] æ ¼å¼
        tool_calls_pattern = r'\[Tool Calls:\s*(\[.*?\])\]'
        match = re.search(tool_calls_pattern, response, re.DOTALL)
        
        if match:
            try:
                tool_calls = json.loads(match.group(1))
                for call in tool_calls:
                    func_name = call.get('name', '')
                    args_str = call.get('arguments', '{}')
                    
                    try:
                        args = json.loads(args_str)
                    except:
                        args = {}
                    
                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    if func_name in TOOL_TO_DEVICE:
                        device = TOOL_TO_DEVICE[func_name]
                        # è·å–ç¬¬ä¸€ä¸ªå‚æ•°å€¼
                        value = list(args.values())[0] if args else None
                        if value is not None:
                            actions.append({
                                "action": "update",
                                "key": device,
                                "value": value
                            })
            except json.JSONDecodeError:
                pass
        
        return actions
    
    @staticmethod
    def _parse_arg_value(args_str: str) -> Any:
        """è§£æå‚æ•°å€¼"""
        args_str = args_str.strip()
        
        # å¤„ç† key=value æ ¼å¼
        if '=' in args_str:
            args_str = args_str.split('=')[-1].strip()
        
        # å»é™¤å¼•å·
        if (args_str.startswith('"') and args_str.endswith('"')) or \
           (args_str.startswith("'") and args_str.endswith("'")):
            return args_str[1:-1]
        
        # å°è¯•è§£æä¸ºæ•°å­—
        try:
            if '.' in args_str:
                return float(args_str)
            return int(args_str)
        except ValueError:
            return args_str


# ============== é»‘ç›’è¯„ä¼°å™¨ ==============

@dataclass
class EvalResult:
    """å•è½®è¯„ä¼°ç»“æœ"""
    turn_id: int
    instruction: str
    agent_response: str
    parsed_actions: List[Dict[str, Any]]
    expected_actions: List[Dict[str, Any]]
    expected_state: Dict[str, Any]
    actual_state: Dict[str, Any]
    score: float
    max_score: float
    passed: bool
    errors: List[str] = field(default_factory=list)


@dataclass
class TestCaseResult:
    """æµ‹è¯•ç”¨ä¾‹è¯„ä¼°ç»“æœ"""
    scenario_id: str
    dimension: str
    difficulty: str
    total_score: float
    max_score: float
    passed: bool
    turn_results: List[EvalResult] = field(default_factory=list)


class BlackBoxEvaluator:
    """
    é»‘ç›’è¯„ä¼°å™¨
    
    ä¸ Agent åªé€šè¿‡æ–‡æœ¬ I/O äº¤äº’ï¼Œä¸è®¿é—® Agent å†…éƒ¨çŠ¶æ€
    """
    
    def __init__(self, env: Optional[SmartHomeEnv] = None):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            env: SmartHome ç¯å¢ƒå®ä¾‹ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
        """
        self.env = env or SmartHomeEnv()
        self.parser = ResponseParser()
    
    def evaluate_turn(
        self,
        agent: AgentInterface,
        instruction: str,
        expected_actions: List[Dict[str, Any]],
        expected_state: Dict[str, Any]
    ) -> EvalResult:
        """
        è¯„ä¼°å•è½®å¯¹è¯
        
        Args:
            agent: Agent å®ä¾‹
            instruction: ç”¨æˆ·æŒ‡ä»¤
            expected_actions: é¢„æœŸåŠ¨ä½œåˆ—è¡¨
            expected_state: é¢„æœŸæœ€ç»ˆçŠ¶æ€
        
        Returns:
            EvalResult è¯„ä¼°ç»“æœ
        """
        # 1. å‘é€æŒ‡ä»¤ç»™ Agent
        # If agent supports injecting expected actions (mock), set them to make smoke tests deterministic
        if hasattr(agent, 'set_expected_actions'):
            try:
                agent.set_expected_actions(expected_actions)
            except Exception:
                pass
        response = agent.chat(instruction)
        
        # 2. è§£æ Agent å“åº”ä¸­çš„åŠ¨ä½œ
        parsed_actions = self.parser.parse(response)
        
        # ä¹Ÿå°è¯•ä½¿ç”¨ Agent è‡ªå·±çš„è§£æ
        agent_parsed = agent.get_tool_calls(response)
        for action in agent_parsed:
            if action not in parsed_actions:
                parsed_actions.append(action)
        
        # 3. æ‰§è¡Œè§£æå‡ºçš„åŠ¨ä½œ
        for action in parsed_actions:
            if action.get('action') == 'update':
                key = action.get('key')
                value = action.get('value')
                if key and value is not None:
                    self.env.update_state(key, value)
                    self.env.record_action(action)
        
        # 4. è·å–å®é™…çŠ¶æ€
        actual_state = self.env.get_state()['state']
        
        # 5. è¯„åˆ†
        evaluator = TurnEvaluator(expected_actions, expected_state)
        actual_actions = self.env.get_action_history()
        result = evaluator.evaluate(actual_actions, actual_state)
        
        return EvalResult(
            turn_id=0,
            instruction=instruction,
            agent_response=response,
            parsed_actions=parsed_actions,
            expected_actions=expected_actions,
            expected_state=expected_state,
            actual_state=actual_state,
            score=result['score'],
            max_score=1.0,
            passed=result['score'] == 1.0,
            errors=result.get('details', {}).get('errors', [])
        )
    
    def evaluate_test_case(
        self,
        agent: AgentInterface,
        test_case: Dict[str, Any]
    ) -> TestCaseResult:
        """
        è¯„ä¼°å®Œæ•´æµ‹è¯•ç”¨ä¾‹
        
        Args:
            agent: Agent å®ä¾‹
            test_case: æµ‹è¯•ç”¨ä¾‹æ•°æ®
        
        Returns:
            TestCaseResult è¯„ä¼°ç»“æœ
        """
        # é‡ç½®
        agent.reset()
        initial_state = test_case.get('initial_state', {})
        self.env.reset(initial_state=initial_state)
        
        turn_results = []
        total_score = 0.0
        max_score = 0.0
        
        for turn in test_case.get('turns', []):
            # é‡ç½® turn å†å²
            self.env.reset_turn_history()
            
            turn_id = turn.get('turn_id', len(turn_results) + 1)
            instruction = turn.get('gm_instruction', '')
            expected_actions = turn.get('expected_agent_action', [])
            expected_state = turn.get('expected_final_state', {})
            
            result = self.evaluate_turn(
                agent=agent,
                instruction=instruction,
                expected_actions=expected_actions,
                expected_state=expected_state
            )
            result.turn_id = turn_id
            
            turn_results.append(result)
            total_score += result.score
            max_score += result.max_score
        
        return TestCaseResult(
            scenario_id=test_case.get('scenario_id', 'unknown'),
            dimension=test_case.get('dimension', 'unknown'),
            difficulty=test_case.get('difficulty', 'unknown'),
            total_score=total_score,
            max_score=max_score,
            passed=total_score == max_score,
            turn_results=turn_results
        )
    
    def evaluate_batch(
        self,
        agent: AgentInterface,
        test_cases: List[Dict[str, Any]],
        verbose: bool = False
    ) -> List[TestCaseResult]:
        """
        æ‰¹é‡è¯„ä¼°æµ‹è¯•ç”¨ä¾‹
        
        Args:
            agent: Agent å®ä¾‹
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            TestCaseResult åˆ—è¡¨
        """
        results = []
        
        for i, case in enumerate(test_cases, 1):
            if verbose:
                print(f"  [{i}/{len(test_cases)}] {case.get('scenario_id', 'unknown')}...", end=" ")
            
            result = self.evaluate_test_case(agent, case)
            results.append(result)
            
            if verbose:
                status = "âœ“" if result.passed else "âœ—"
                print(f"{status} ({result.total_score}/{result.max_score})")
        
        return results
    
    def get_tools_schema_openai(self) -> List[dict]:
        """
        è·å– OpenAI æ ¼å¼çš„å·¥å…·å®šä¹‰
        
        Agent å¯ä»¥ä½¿ç”¨æ­¤å®šä¹‰æ¥æ³¨å†Œå·¥å…·
        """
        tools = []
        
        for func_name, func_info in TOOL_FUNCTIONS.items():
            tool = {
                "type": "function",
                "function": {
                    "name": func_name,
                    "description": func_info["description"],
                    "parameters": {
                        "type": "object",
                        "properties": func_info["parameters"],
                        "required": list(func_info["parameters"].keys())
                    }
                }
            }
            tools.append(tool)
        
        return tools
    
    def get_tools_description_text(self) -> str:
        """
        è·å–å·¥å…·çš„æ–‡æœ¬æè¿°
        
        ç”¨äºåœ¨ prompt ä¸­å‘Šè¯‰ Agent å¯ç”¨çš„å·¥å…·
        """
        lines = ["Available tools:\n"]
        
        for func_name, func_info in TOOL_FUNCTIONS.items():
            params = func_info["parameters"]
            params_str = ", ".join(
                f"{k}: {v.get('type', 'any')}" 
                for k, v in params.items()
            )
            lines.append(f"- {func_name}({params_str}): {func_info['description']}")
        
        return "\n".join(lines)


# ============== ä¾¿æ·å‡½æ•° ==============

def quick_evaluate(
    agent_type: str,
    test_cases: List[Dict[str, Any]],
    verbose: bool = True,
    **agent_kwargs
) -> Tuple[List[TestCaseResult], Dict[str, Any]]:
    """
    å¿«é€Ÿè¯„ä¼°å‡½æ•°
    
    Args:
        agent_type: Agent ç±»å‹ ("openai", "ollama", "purple", "mock", etc.)
        test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        **agent_kwargs: Agent å‚æ•°
    
    Returns:
        (results, summary) å…ƒç»„
    
    Example:
        results, summary = quick_evaluate(
            "openai", 
            test_cases,
            model="gpt-4o",
            api_key="sk-..."
        )
    """
    # åˆ›å»º Agent
    agent = create_agent(agent_type, **agent_kwargs)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = BlackBoxEvaluator()
    
    if verbose:
        print(f"ğŸ” Evaluating {agent.name} on {len(test_cases)} test cases...")
    
    # è¯„ä¼°
    results = evaluator.evaluate_batch(agent, test_cases, verbose=verbose)
    
    # ç»Ÿè®¡
    total = len(results)
    passed = sum(1 for r in results if r.passed)
    total_score = sum(r.total_score for r in results)
    max_score = sum(r.max_score for r in results)
    
    summary = {
        "agent_name": agent.name,
        "total_cases": total,
        "passed": passed,
        "failed": total - passed,
        "pass_rate": passed / max(1, total),
        "total_score": total_score,
        "max_score": max_score,
        "score_rate": total_score / max(1, max_score)
    }
    
    if verbose:
        print(f"\nğŸ“Š Summary:")
        print(f"   Pass Rate: {summary['pass_rate']*100:.1f}% ({passed}/{total})")
        print(f"   Score Rate: {summary['score_rate']*100:.1f}%")
    
    return results, summary


# ============== æµ‹è¯• ==============

if __name__ == "__main__":
    # æµ‹è¯•è§£æå™¨
    print("Testing ResponseParser...")
    
    test_responses = [
        '{"action": "update", "key": "living_room_light", "value": "on"}',
        'I will turn on the light. manage_living_room_light("on")',
        'Setting temperature to 24. {"action": "update", "key": "ac_temperature", "value": 24}',
        '[Tool Calls: [{"name": "manage_ac_temperature", "arguments": "{\"temperature\": 25}"}]]'
    ]
    
    for resp in test_responses:
        actions = ResponseParser.parse(resp)
        print(f"  Input: {resp[:50]}...")
        print(f"  Parsed: {actions}\n")
    
    # æµ‹è¯•è¯„ä¼°å™¨
    print("\nTesting BlackBoxEvaluator with MockAgent...")
    from green_agent.agent_interface import MockAgent
    
    agent = MockAgent(error_rate=0.0)
    evaluator = BlackBoxEvaluator()
    
    # ç®€å•æµ‹è¯•ç”¨ä¾‹
    test_case = {
        "scenario_id": "test_001",
        "dimension": "precision",
        "difficulty": "easy",
        "initial_state": {"living_room_light": "off"},
        "turns": [
            {
                "turn_id": 1,
                "gm_instruction": "Turn on the living room light",
                "expected_agent_action": [
                    {"action": "update", "key": "living_room_light", "value": "on"}
                ],
                "expected_final_state": {"living_room_light": "on"}
            }
        ]
    }
    
    # è®¾ç½® Mock Agent çš„é¢„æœŸåŠ¨ä½œ
    agent.set_expected_actions([
        {"action": "update", "key": "living_room_light", "value": "on"}
    ])
    
    result = evaluator.evaluate_test_case(agent, test_case)
    print(f"  Result: {'PASS' if result.passed else 'FAIL'}")
    print(f"  Score: {result.total_score}/{result.max_score}")
